{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\marlo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load National Research Council"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"NRC-Emotion-Lexicon/NRC-Emotion-Lexicon/NRC-Emotion-Lexicon-Wordlevel-v0.92.txt\"\n",
    "nrc_lexicon = {}\n",
    "with open(file_path, newline='') as csvfile:\n",
    "    text = csv.reader(csvfile, delimiter='\\t', quotechar='|')\n",
    "    for row in text:\n",
    "        if int(row[2]) == 1:\n",
    "            if row[0] not in nrc_lexicon.keys():\n",
    "                nrc_lexicon[row[0]] = []\n",
    "            nrc_lexicon[row[0]].append(row[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abacus ['trust']\n",
      "abandon ['fear', 'negative', 'sadness']\n",
      "abandoned ['anger', 'fear', 'negative', 'sadness']\n",
      "abandonment ['anger', 'fear', 'negative', 'sadness', 'surprise']\n",
      "abba ['positive']\n"
     ]
    }
   ],
   "source": [
    "# Vista primors 5 elementos del diccionario\n",
    "for k,v in list(nrc_lexicon.items())[:5]:\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extender el léxico NRC utilizando WordNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_to_penn = {\n",
    " 'n': 'NN', # sustantivo\n",
    " 'v': 'VB', # verbo\n",
    " 'a': 'JJ', # adjetivo\n",
    " 's': 'JJ', # adjetivo superlativo\n",
    " 'r': 'RB', # adverbio\n",
    " 'c': 'CC' # conjunción\n",
    "}\n",
    "\n",
    "penn_to_wordnet = {\n",
    " 'CC': 'c', # Coordinating conjunction\n",
    " 'CD': 'c', # Cardinal number\n",
    " 'DT': 'c', # Determiner\n",
    " 'EX': 'c', # Existential there\n",
    " 'FW': 'x', # Foreign word\n",
    " 'IN': 'c', # Preposition or subordinating conjunction\n",
    " 'JJ': 'a', # Adjective\n",
    " 'JJR': 'a', # Adjective, comparative\n",
    " 'JJS': 'a', # Adjective, superlative\n",
    " 'LS': 'c', # List item marker\n",
    " 'MD': 'v', # Modal\n",
    " 'NN': 'n', # Noun, singular or mass\n",
    " 'NNS': 'n', # Noun, plural\n",
    " 'NNP': 'n', # Proper noun, singular\n",
    " 'NNPS': 'n', # Proper noun, plural\n",
    "  'PDT': 'c', # Predeterminer\n",
    " 'POS': 'c', # Possessive ending\n",
    " 'PRP': 'n', # Personal pronoun\n",
    " 'PRP$': 'n', # Possessive pronoun\n",
    " 'RB': 'r', # Adverb\n",
    " 'RBR': 'r', # Adverb, comparative\n",
    " 'RBS': 'r', # Adverb, superlative\n",
    " 'RP': 'r', # Particle\n",
    " 'SYM': 'x', # Symbol\n",
    " 'TO': 'c', # to\n",
    " 'UH': 'x', # Interjection\n",
    " 'VB': 'v', # Verb, base form\n",
    " 'VBD': 'v', # Verb, past tense\n",
    " 'VBG': 'v', # Verb, gerund or present participle\n",
    " 'VBN': 'v', # Verb, past participle\n",
    " 'VBP': 'v', # Verb, non-3rd person singular present\n",
    " 'VBZ': 'v', # Verb, 3rd person singular present\n",
    " 'WDT': 'c', # Wh-determiner\n",
    " 'WP': 'n', # Wh-pronoun\n",
    " 'WP$': 'n', # Possessive wh-pronoun\n",
    " 'WRB': 'r', # Wh-adverb\n",
    " 'X': 'x' # Any word not categorized by the other tags\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penn_to_wordnet_pos(penn_pos):\n",
    "    return penn_to_wordnet.get(penn_pos, None)\n",
    "\n",
    "def get_wordnet_relations(word, pos):\n",
    "    pos = penn_to_wordnet_pos(pos)\n",
    "    if pos:\n",
    "        synsets = wn.synsets(word, pos=pos)\n",
    "        print(synsets)\n",
    "    # if pos:\n",
    "    #     synsets = wn.synsets(word, pos=pos)\n",
    "    #     related_words = set()\n",
    "    #     for synset in synsets:\n",
    "    #         related_words.update(synset.lemma_names())\n",
    "    #         related_words.update([lemma.name() for lemma in synset.lemmas()])\n",
    "    #         related_words.update([hyper.name().split('.')[0] for hyper in synset.hypernyms()])\n",
    "    #         related_words.update([hypo.name().split('.')[0] for hypo in synset.hyponyms()])\n",
    "    #         related_words.update([lemma.name() for lemma in synset.lemmas() if lemma.derivationally_related_forms()])\n",
    "    #     return related_words\n",
    "    # else:\n",
    "    #     return set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Synset('joy.n.01'), Synset('joy.n.02')]\n"
     ]
    }
   ],
   "source": [
    "get_wordnet_relations('joy', 'WP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended_lexicon = {}\n",
    "\n",
    "for word, emotions in nrc_lexicon.items():\n",
    "    for pos in ['n', 'v', 'a', 'r']:  # Consideramos solo sustantivos, verbos, adjetivos y adverbios\n",
    "        related_words = get_wordnet_relations(word, pos)\n",
    "        for related_word in related_words:\n",
    "            extended_lexicon.setdefault((related_word, pos), []).extend(emotions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Lemma('joyous.a.01.joyous'),\n",
       " Lemma('gladden.v.01.joy'),\n",
       " Lemma('rejoice.v.01.joy')]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wn.synset('joy.n.01').lemmas()[0].derivationally_related_forms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joy', 'joyousness', 'joyfulness']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[str(lemma.name()) for lemma in wn.synset('joy.n.01').lemmas()]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
